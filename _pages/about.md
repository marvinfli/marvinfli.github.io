---
permalink: /
title: "Hi, my name is Marvin."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm an AI researcher thinking about the **theory and science of generative models**, especially in the context of **reinforcement learning for language models**. Earlier this year I graduated *summa cum laude* from Harvard with a B.A. in Computer Science & Mathematics.

My most recent project was on a unified theoretical framework for feature emergence in generative models (**ICML 2024; ICML 2025 oral**). We explained where high-level features such as reasoning accuracy and toxicity emerge during the sampling trajectories of diffusion models and large language models. This work, also presented in my [thesis](/files/thesis.pdf), was awarded both the **Hoopes Prize** for outstanding undergraduate research and the **Captain Jonathan Fay Prize**, given to the top three theses across all disciplines at Harvard College.

I love meeting new people and chatting. Please reach out at marvin[dot]fangzhou[dot]li[at]gmail.com.


# Selected Publications  
\* denotes equal contribution

**[Blink of an Eye: A Simple Theory for Feature Localization in Generative Models](https://ar5iv.org/abs/2502.00921)**  
**Marvin Li**, Aayush Karan, Sitan Chen.  
*ICML*, 2025 <span style="color:#d55e5e;">(Oral, top 1% of submissions)</span>  
[arXiv](https://ar5iv.org/abs/2502.00921) / [code](https://github.com/marvinfli/critical-windows-lm)  
A unifying theory showing why and when features suddenly “lock in” during generation in both diffusion and autoregressive models.  

**[Critical Windows: Non-Asymptotic Theory for Feature Emergence in Diffusion Models](https://ar5iv.org/abs/2403.01633)**  
**Marvin Li**, Sitan Chen.  
*ICML*, 2024 \
[arXiv](https://ar5iv.org/abs/2403.01633) / [code](https://github.com/marvinli-harvard/critical-windows) \
Introduces tight, distribution-agnostic bounds pinpointing when image features appear along the diffusion trajectory.  


**[MoPe: Model Perturbation-Based Privacy Attacks on Language Models](https://aclanthology.org/2023.emnlp-main.842)**  
**Marvin Li**\*, Jason Wang\*, Jeffrey Wang\*, Seth Neel.  
*EMNLP* Main Conference, 2023 \
[arXiv](https://arxiv.org/abs/2310.14369)\
Shows that second-order gradient information lets an attacker detect training-set membership far more reliably than loss-only baselines.  

